import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    roc_auc_score,
    precision_recall_curve,
    average_precision_score
)

from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.ensemble import RandomForestClassifier
import joblib


def load_data(csv_path: str) -> pd.DataFrame:
    return pd.read_csv(csv_path)


def engineer_features(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()

    df["expected_newbalance"] = df["oldbalance"] - df["amount"]
    df["balance_delta"] = df["expected_newbalance"] - df["newbalance"]
    df["abs_balance_delta"] = df["balance_delta"].abs()
    df["is_balance_mismatch"] = (df["abs_balance_delta"] > 1e-2).astype(int)

    df["relative_amount"] = np.where(
        df["oldbalance"] > 0,
        df["amount"] / df["oldbalance"],
        0.0
    )

    def tenure_bucket(m):
        if m < 6:
            return "new"
        elif m < 24:
            return "regular"
        elif m < 60:
            return "loyal"
        else:
            return "very_loyal"

    df["tenure_bucket"] = df["customer_tenure_months"].apply(tenure_bucket)

    return df


def train_fraud_model(csv_path: str):
    df = load_data(csv_path)
    df = engineer_features(df)

    feature_cols = [
        "amount",
        "oldbalance",
        "newbalance",
        "is_international",
        "is_high_risk_country",
        "customer_tenure_months",
        "has_chargeback_history",
        "expected_newbalance",
        "balance_delta",
        "abs_balance_delta",
        "is_balance_mismatch",
        "relative_amount",
        "transaction_type",
        "tenure_bucket"
    ]

    X = df[feature_cols]
    y = df["is_fraud"]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )

    numeric_features = [
        "amount", "oldbalance", "newbalance",
        "is_international", "is_high_risk_country",
        "customer_tenure_months", "has_chargeback_history",
        "expected_newbalance", "balance_delta",
        "abs_balance_delta", "is_balance_mismatch", "relative_amount"
    ]

    categorical_features = ["transaction_type", "tenure_bucket"]

    preprocessor = ColumnTransformer(
        transformers=[
            ("num", "passthrough", numeric_features),
            ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_features),
        ]
    )

    # ðŸ”¥ FIXED: SMOTE AUTO, NO ERROR
    smote = SMOTE(sampling_strategy="auto", random_state=42)

    model = RandomForestClassifier(
        n_estimators=250,
        random_state=42,
        class_weight="balanced_subsample"
    )

    clf = ImbPipeline(
        steps=[
            ("preprocessor", preprocessor),
            ("smote", smote),
            ("model", model),
        ]
    )

    print("\nTraining fraud detection model...")
    clf.fit(X_train, y_train)

    y_proba = clf.predict_proba(X_test)[:, 1]
    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)
    best_threshold = 0.5  # Default

    for r, t in zip(recall, np.append(thresholds, 1.0)):
        if r >= 0.90:
            best_threshold = t
            break

    y_pred = (y_proba >= best_threshold).astype(int)

    print("\n=== MODEL EVALUATION ===")
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("\nClassification Report:\n", classification_report(y_test, y_pred))
    print("\nROC-AUC:", roc_auc_score(y_test, y_proba))
    print("PR-AUC:", average_precision_score(y_test, y_proba))

    joblib.dump(clf, "fraud_detection_model.joblib")
    np.save("fraud_threshold.npy", np.array([best_threshold]))

    print("\nModel saved: fraud_detection_model.joblib")
    print("Threshold saved: fraud_threshold.npy")

    return clf, best_threshold


def score_new_transactions(model_path: str, threshold_path: str, csv_path: str) -> pd.DataFrame:
    clf = joblib.load(model_path)
    threshold = float(np.load(threshold_path)[0])

    df_new = load_data(csv_path)
    df_new = engineer_features(df_new)

    feature_cols = [
        "amount","oldbalance","newbalance","is_international","is_high_risk_country",
        "customer_tenure_months","has_chargeback_history","expected_newbalance",
        "balance_delta","abs_balance_delta","is_balance_mismatch","relative_amount",
        "transaction_type","tenure_bucket"
    ]

    proba = clf.predict_proba(df_new[feature_cols])[:, 1]
    pred = (proba >= threshold).astype(int)

    df_new["fraud_probability"] = proba
    df_new["risk_score"] = (proba * 100).round(2)

    def level(p):
        if p >= 0.80: return "HIGH"
        if p >= 0.40: return "MEDIUM"
        return "LOW"

    df_new["risk_level"] = df_new["fraud_probability"].apply(level)
    df_new["predicted_is_fraud"] = pred

    return df_new


if __name__ == "__main__":
    trained_model, threshold = train_fraud_model("C:/Users/ks255/Downloads/sample_transactions.csv")

    # For new unseen transactions, just uncomment:
    #
    # scored = score_new_transactions(
    #     "fraud_detection_model.joblib",
    #     "fraud_threshold.npy",
    #     "C:/Users/ks255/Downloads/new_transactions.csv"
    # )
    # print(scored.head())

